apiVersion: v1
kind: ConfigMap
metadata:
  name: ollama-config
  namespace: default
data:
  Modelfile: |
    FROM llama3.2
    # set the temperature to 1 [higher is more creative, lower is more coherent]
    PARAMETER temperature 1
    # set the system message
    SYSTEM """
    You are a COMINT Expert and act as external observer. Your answers consider the parcipants and the time frame of any events and communcations.
    """
  ModelfileMistral: |
    FROM cas/mistral-instruct-v0.2-2x7b-moe:latest
    # set the temperature to 1 [higher is more creative, lower is more coherent]
    PARAMETER temperature 1
    # set the system message
    SYSTEM """
    You are a helpful teacher. Your answers aim to help to solve the question with step by step instructions.
    """
  ModelfileGemma3tool: |
    FROM gemma3:4b
    TEMPLATE """{{- if .Messages }}
    {{- if or .System .Tools }}<start_of_turn>user
    {{- if .System}}
    {{ .System }}
    {{- end }}
    {{- if .Tools }}
    # Tools
    You may call one or more functions to assist with the user query.
    You are provided with function signatures within <tools></tools> XML tags:
    <tools>
    
    {{- range $.Tools }}
    {"type": "function", "function": {{ .Function }}}
    {{- end }}
    </tools>
    
    For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
    <tool_call>
    {"name": <function-name>, "arguments": <args-json-object>}
    </tool_call>
    {{- end }}<end_of_turn>
    {{ end }}
    {{- range $i, $_ := .Messages }}
    {{- $last := eq (len (slice $.Messages $i)) 1 -}}
    {{- if eq .Role "user" }}<start_of_turn>user
    {{ .Content }}<end_of_turn>
    {{ else if eq .Role "assistant" }}<start_of_turn>model
    {{ if .Content }}{{ .Content }}
    {{- else if .ToolCalls }}<tool_call>
    {{ range .ToolCalls }}{"name": "{{ .Function.Name }}", "arguments": {{ .Function.Arguments}}}
    {{ end }}</tool_call>
    {{- end }}{{ if not $last }}<end_of_turn>
    {{ end }}
    {{- else if eq .Role "tool" }}<start_of_turn>user
    <tool_response>
    {{ .Content }}
    </tool_response><end_of_turn>
    {{ end }}
    {{- if and (ne .Role "assistant") $last }}<start_of_turn>model
    {{ end }}
    {{- end }}
    {{- else }}
    {{- if .System }}<start_of_turn>user
    {{ .System }}<end_of_turn>
    {{ end }}{{ if .Prompt }}<start_of_turn>user
    {{ .Prompt }}<end_of_turn>
    {{ end }}<start_of_turn>model
    {{ end }}{{ .Response }}{{ if .Response }}<end_of_turn>{{ end }}"""
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  labels:
    app: ollama
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
  template:
    metadata:
      labels:
        app: ollama
    spec:
      containers:
      - name: ollama
        image: ollama/ollama
        imagePullPolicy: IfNotPresent  # Only pull image if not present locally
        env:
        - name: OLLAMA_CONTEXT_LENGTH
          value: "8192"
        - name: OLLAMA_NUM_PARALLEL
          value: "1"
        ports:
        - containerPort: 11434
        volumeMounts:
        - name: ollama-data
          mountPath: /root/.ollama
        - name: ollama-config
          mountPath: /root/model
        resources:
          limits:
            nvidia.com/gpu: 1  # Equivalent to --gpus=all
      volumes:
      - name: ollama-data
        persistentVolumeClaim:
          claimName: ollama-pvc
      - name: ollama-config
        configMap:
          name: ollama-config
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-service
spec:
  selector:
    app: ollama
  ports:
  - protocol: TCP
    port: 11434
    targetPort: 11434
  type: NodePort
---
apiVersion: v1
kind: Service
metadata:
  name: ollama-service-internal
spec:
  selector:
    app: ollama
  ports:
  - protocol: TCP
    port: 11433
    targetPort: 11434
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ollama-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: charon
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: ollama-service
            port:
              number: 11433
